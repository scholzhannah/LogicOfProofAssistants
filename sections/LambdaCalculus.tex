\section{\texorpdfstring{$\lambda$}{lambda}-calculus}

\begin{boxdefi}
    Let $\alert{\fV} = \{ x_0, x_1, \dots \} $ a countably infinite set of variables and $\alert{C} = \{ c_0, c_1, \dots \}$ be any set of constants. 
    The terms of the \alert{$\lambda$-calculus} are given by the following BNF: 
    \begin{equation*}
        s,t \Coloneqq x \mid c \mid (s t) \mid (\lambda x. t)
    \end{equation*}
    where $x$ is a variable and $c$ a constant.
\end{boxdefi}

\begin{rem}
    \hfill
    \begin{enumerate}
        \item Think of $(\lambda x. t)$ as the function $x \mapsto t(x)$ and $(s t)$ as function application. 
        \item Anything can apply to any term, e.g. $(x x)$ is a term.
        \item Abbreviate $((rs)t)u$ to $rstu$ and $\lambda x. \lambda y. \lambda z. t$ to $\lambda x y z. t$. For example, $\lambda xy. xy$ means $(\lambda x. (\lambda y. (x y)))$.
        \item $\lambda x.t$ binds the variable $x$. Like in first-order logic we can define $\alpha$-equivalence ($\aeq$) and substitution ($t[s/x]$). Here we identify $\alpha$-equivalent terms, e.g. $\lambda x.x = \lambda y.y$.
    \end{enumerate}
\end{rem}

\begin{example}
    $(x(\lambda x.x))[s/x] = s(\lambda x.x)$
\end{example}

\begin{rem}
    Consider $(\lambda x. t) s$. 
    We want this to correspond to $t[s/x]$. 
\end{rem}

\begin{boxdefi}
    \hfill
    \begin{enumerate}
        \item \alert{$\beta$-contraction ($\becont$)} is defined as $(\lambda x. t) s \becont t [s/x]$.
        \item {\alert{One-step-$\beta$-reduction ($\beored$)} is defined as the compatible closure if $\becont$, i.e.
            \begin{enumerate}
                \item If $s \becont t$ then $s \beored t$.
                \item If $s \beored t$ then $su \beored tu$, $us \beored ut$ and $\lambda x. s \beored \lambda x. t$.
            \end{enumerate}}
        \item \alert{$\beta$-reduction ($\bered$)} is the reflexive transitive closure of $\beored$, i.e. it is the smallest relation that is reflexive, transitive and contains $\beored$.
        \item \alert{$\beta$-equivalence ($\beq$)} is the smallest equivalence relation containing $\bered$.
    \end{enumerate}
\end{boxdefi}

\begin{example}\label{ex:betared}
    \hfill
    \begin{enumerate}
        \item $(\lambda x. xxy)(yz) \becont yz(yz)y$
        \item \adjustbox{valign=t}{
            \begin{tikzcd}
                (\lambda x. xx)y((\lambda z. yz)(ww))  \ar[r, "{\beta , 1}"] \ar[d, "{\beta , 1}"] & (\lambda x.xx)y(y(ww)) \ar[d, "{\beta , 1}"] \\
                yy ((\lambda z. yz)(ww)) \ar[r, "{\beta , 1}"] & yy (y(ww)) \\
            \end{tikzcd}}
            \vspace{-2em}
        \item $(\lambda x.xx) (\lambda x. xx) \beored (\lambda x.xx) (\lambda x. xx)$
    \end{enumerate}
\end{example}

\begin{boxdefi}
    We define the following combinators: 
    \begin{enumerate}
        \item $\alert{I} = \lambda x.x$
        \item $\alert{K} = \lambda xy.x$
        \item $\alert{K_*} = \lambda xy.y$
        \item $\alert{S} = \lambda xyz.xz(yz)$
    \end{enumerate}
\end{boxdefi}

\begin{rem}
    Every term can be defined using $K$ and $S$ up to $\beta$-equivalence.
\end{rem}

\begin{example}
    $SKK \bered \lambda z. Kz(Kz) \bered \lambda z.z = I$.
\end{example}

\begin{boxprop} \label{prop:fixpoi}
    There exists a \alert{fixed-point combinator} $Y$ such that $Y t \bered t(Yt)$.
\end{boxprop}
\begin{proof}
    Let $A \coloneq \lambda fx. x(ffx)$ and let $Y \coloneq AA$ be the \alert{Turing operator}.
    Then $Yt = AAt \bered t (AAt) = t(Yt)$.
\end{proof}

\begin{boxdefi}
    We can define the \alert{pairing} $\alert{P} \coloneq \lambda stx.xst$ and denote $\alert{(s, t)} \coloneq Pst \bered \lambda x. xst$.
\end{boxdefi}

\begin{rem}
    Naming this a pairing makes sense because we have $(s, t) K \bered Kst \bered s$ and $(s, t) K_* \bered K*(s, t) \bered t$.
\end{rem}

\begin{boxdefi}
    We can define \alert{Church numerals}. 
    If $n$ is a natural number we encode it as $\alert{[n]} \coloneq \lambda fx. f^n x$ where $f^0 x \coloneq x$ and $f^{n+1} x = f(f^nx) = f^n(fx)$.
\end{boxdefi}

\begin{boxdefi}
    Let $A$ be a set and $\ored$ a binary relation on $A$ with reflective transitive closure $\to$.
    \begin{enumerate}
        \item $t \in A$ is \alert{in normal form} if there is no $s$ such that $t \ored s$.
        \item $t \in A$ \alert{has normal form $s$} if $s$ is in normal form and $t \to s$.
        \item $t \in A$ is \alert{strongly normalizing} if there exists no infinite sequence $t \ored t_1 \ored t_2 \ored t_3 \ored \cdots$.
        \item $\ored$ is \alert{(weakly) normalizing} if every $t \in A$ has a normal form.
        \item $\ored$ is \alert{strongly normalizing} if every $t \in A$ is strongly normalizing.
        \item {$\ored$ is \alert{confluent} (has the \alert{Church-Rosser property}) if whenever $u \leftarrow t \to v$ there is an $s \in A$ with $u \to s \leftarrow v$.
            \begin{equation*}
            \begin{tikzcd}[ampersand replacement=\&]
                t \ar[r] \ar[d] \& v \ar[d, dashed] \\
                u \ar[r, dashed] \& s 
            \end{tikzcd}
        \end{equation*}}
    \end{enumerate}
\end{boxdefi}

\begin{rem}
    $\beta$-reduction is neither weakly nor strongly normalizing.
\end{rem}
\begin{proof}
    See the counterexamples presented in Example \ref{ex:betared} (iii) and Proposition \ref{prop:fixpoi}.
\end{proof}

\begin{boxthm}[Church-Rosser] \label{thm:ChurchRosser}
    $\beored$ is confluent.
\end{boxthm}

\begin{rem}
    It does not suffice to prove 
    \begin{equation*}
        \begin{tikzcd}
            t \ar[r, "{\beta, 1}"] \ar[d, "{\beta, 1}"] & v \ar[d, dashed, "\beta"] \\
            u \ar[r, dashed, "\beta"] & s 
        \end{tikzcd}
    \end{equation*}
    i.e. for a general binary relation Theorem \ref{thm:ChurchRosser} does not follow from this.
\end{rem}

\begin{boxdefi} \label{def:parared}
    \alert{Parallel reduction ($\Rightarrow$)} is defined inductively as
    \begin{enumerate}
        \item $x \Rightarrow x$ and $c \Rightarrow c$ where $x$ is a variable and $c$ is a constant.
        \item If $t \Rightarrow t'$ then $\lambda x.t \Rightarrow \lambda x. t'$.
    \end{enumerate}
    If $t \Rightarrow t'$ and $u \Rightarrow u'$ then 
    \begin{enumerate}[resume]
        \item $tu \Rightarrow t'u'$.
        \item $(\lambda x.t)u \Rightarrow t'[u'/x]$.
    \end{enumerate}
\end{boxdefi}

\begin{boxlem}
    Parallel induction is reflexive, i.e. $t \Rightarrow t$.
\end{boxlem}
\begin{proof}
    We show this by induction on $t$. 
    Consider $t = \lambda x.s$. 
    Then by induction hypothesis $s \Rightarrow s$, so by Definition \ref{def:parared} (ii) $\lambda x.s \Rightarrow \lambda x.s$.
    The rest of the cases are similar.
\end{proof}

\begin{boxlem} \label{lem:beoredtoarrow}
    If $t \beored s$ then $t \Rightarrow s$.
\end{boxlem}
\begin{proof}
    We show this by induction on $t \beored s$.
    If $t \becont s$, say $(\lambda x.u)v \becont u [v/x]$. 
    Then $(\lambda x. u)v \Rightarrow u [v/x]$ by Definition \ref{def:parared} (iv).
    The other cases are also easy to show.
\end{proof}

\begin{boxlem} \label{lem:arrowbered}
    If $t \Rightarrow t'$ then $t \bered t'$.
\end{boxlem}
\begin{proof}
    We show this by induction on $t \Rightarrow t'$.
    Suppose the last rule was Definition \ref{def:parared} (iv), i.e. concluding $(\lambda x.t)u \Rightarrow t'[u'/x]$ from $t \Rightarrow t'$ and $u \Rightarrow u'$.
    By induction hypothesis we have $t \bered t'$ and $u \bered u'$.
    Then $(\lambda x.t)u \bered (\lambda x.t') u \bered (\lambda x. t') u' \beored t'[u'/x]$.
    The other cases are similar.
\end{proof}

\begin{boxlem} \label{lem:arrowsubst}
    If $t \Rightarrow t'$ and $w \Rightarrow w'$ then $t[w/y] \Rightarrow t'[w'/y]$.
\end{boxlem}
\begin{proof}
    We show this by induction on $t \Rightarrow t'$.
    Suppose the last step was Definition \ref{def:parared} (iv), i.e. concluding $(\lambda x.t)u \Rightarrow t'[u'/x]$ from $t \Rightarrow t'$ and $u \Rightarrow u'$.
    By induction hypothesis we know that $t[w/y] \Rightarrow t'[w/y]$ and $u[w /y] \Rightarrow u'[w/y]$.
    We have to show $(\lambda x.t [w/y])u[w/y] \Rightarrow t'[u'/x][w'/y]$.
    $x$ is bound so we may assume that $x$ is not free in $w'$. 
    Then one can prove that $t'[u'/x][w'/y] = t'[w'/y][(u'[w'/y])/x]$.
    Now the claim follows from Definition \ref{def:parared} (iv).
    The rest of the cases are similar.
\end{proof}

\begin{boxdefi} \label{def:star}
    If $t$ is a term then \alert{$t^*$} is recursively defined as 
    \begin{enumerate}
        \item $x^* = x$ and $c^* = c$ for variables $x$ and constants $c$.
        \item $(\lambda x.t)^* = \lambda x. t^*$.
        \item $(ts)^* = t^*s^*$ if $t$ is not a $\lambda$.
        \item $((\lambda x.t) s)^* = t^*[s^*/x]$.
    \end{enumerate}
\end{boxdefi}

\begin{boxlem} \label{lem:arrowstar}
    If $s \Rightarrow t$ then $t \Rightarrow s^*$.
\end{boxlem}
\begin{proof}
    We show this by induction of the length of the derivation for $s \Rightarrow t$.

    If the last step was Definition \ref{def:parared} (iii), i.e. concluding $tu \Rightarrow t'u'$ from $t \Rightarrow t'$ and $u \Rightarrow u'$, then by induction hypothesis $t' \Rightarrow t^*$ and $u' \Rightarrow u^*$.
    We need to show that $t'u' \Rightarrow (t u)^*$.
    If $t$ is not a $\lambda$ then $(tu)^* = t^*u^*$, so we are done by Definition \ref{def:parared} (iii).
    If $t = \lambda x. s$ then $(tu)^* = s^* [u*/x]$.
    We know $\lambda x.s \Rightarrow t'$ which can only be derived using Definition \ref{def:parared} (ii). 
    So $t' = \lambda x. s'$ with $s \Rightarrow s'$.
    By induction hypothesis $s' \Rightarrow s^*$. 
    Then $(\lambda x. s') u' \Rightarrow s^* [u*/x]$ follows from Definition \ref{def:star} (iv).

    If the last step was Definition \ref{def:parared} (iv), i.e. concluding $(\lambda x.t) u \Rightarrow t'[u'/x]$ from $t \Rightarrow t'$ and $u \Rightarrow u'$, then by induction hypothesis we know that $t' \Rightarrow t^*$ and $u' \Rightarrow u^*$.
    Then $t'[u'/x] \Rightarrow ((\lambda x.t)u)^* = t^*[u^* /x]$ by Lemma \ref{lem:arrowsubst}.

    The rest of the cases are easy.
\end{proof}

\begin{boxlem}\label{lem:almostconfluence}
    If $t \beored u$ and $t \bered v$ then there is an $s$ with $u \bered s \prescript{}{\beta}{\leftarrow} v$.
    \begin{equation*}
        \begin{tikzcd}[ampersand replacement=\&]
            t \ar[r, "\beta"] \ar[d, "{\beta, 1}"] \& v \ar[d, dashed, "\beta"] \\
            u \ar[r, dashed, "\beta"] \& s 
        \end{tikzcd}
    \end{equation*}
\end{boxlem}
\begin{proof}
    Decomposing $t \bered v$ into individual steps gives us
    \begin{equation*}
        \begin{tikzcd}[/tikz/cells={/tikz/nodes={shape=asymmetrical
            rectangle,text width=0.5cm,text height=2ex,text depth=0.3ex,align=center}}]
            & t \ar[dl, "{\beta, 1}"] \ar[dr, "{\beta, 1}"] & \\
            u && v_1 \ar[dr, "{\beta, 1}"] \\
            &&& v_2 \ar[dr, "{\beta, 1}"] \\
            &&&& \ddots \ar[dr, "{\beta, 1}"] \\
            &&&&& \mathllap{v_n} = \mathrlap{v}
        \end{tikzcd}
    \end{equation*}
    which with Lemma \ref{lem:beoredtoarrow} becomes
    \begin{equation*}
        \begin{tikzcd}[/tikz/cells={/tikz/nodes={shape=asymmetrical
            rectangle,text width=0.5cm,text height=2ex,text depth=0.3ex,align=center}}]
            & t \ar[dl, Rightarrow] \ar[dr, Rightarrow] & \\
            u && v_1 \ar[dr, Rightarrow] \\
            &&& v_2 \ar[dr, Rightarrow] \\
            &&&& \ddots \ar[dr, Rightarrow] \\
            &&&&& \mathllap{v_n} = \mathrlap{v}
        \end{tikzcd}
    \end{equation*}
    which with Lemma \ref{lem:arrowstar} yields
    \begin{equation*}
        \begin{tikzcd}[/tikz/cells={/tikz/nodes={shape=asymmetrical
            rectangle,text width=0.5cm,text height=2ex,text depth=0.3ex,align=center}}]
            & t \ar[dl, Rightarrow] \ar[dr, Rightarrow] & \\
            u \ar[dr, Rightarrow] && v_1 \ar[dr, Rightarrow] \ar[dl, Rightarrow] \\
            & t^* \ar[dr, Rightarrow] && v_2 \ar[dr, Rightarrow] \ar[dl, Rightarrow] \\
            && v_1^* \ar[dr, Rightarrow] && \ddots \ar[dr, Rightarrow] \\
            &&& \ddots \ar[dr, Rightarrow] && \mathllap{v_n} = \mathrlap{v} \ar[dl, Rightarrow]\\
            &&&&\mathllap{v}_{n\mathrlap{-1}}^*
        \end{tikzcd}
    \end{equation*}
    which implies our desired statement since by Lemma \ref{lem:arrowbered} parallel reduction implies $\beta$-reduction and $\beta$-reduction is transitive. 
\end{proof}

\begin{exercise}
    Derive Theorem \ref{thm:ChurchRosser} (Church-Rosser) from Lemma \ref{lem:almostconfluence}.
\end{exercise}

\begin{boxcor}
    Every term $t$ has at most one $\beta$-normal form.
\end{boxcor}

\begin{boxcor}
    If $s \beq t$, then there is $u$ such that $s \bered u \prescript{}{\beta}{\leftarrow} t$.
\end{boxcor}

\subsection{Partial recursive functions}

\begin{boxdefi}
    Let $\alert{A \rightharpoonup B}$ be the set of \alert{partial functions} from $A$ to $B$, i.e. a partial function from $A$ to $B$ is a pair $(X, f)$ such that $X \subseteq A$ and $f \colon X \to B$.
    We set $\alert{\domain{f}} \coloneq X$ and call it the \alert{domain} of $f$.
\end{boxdefi}

\begin{notation}
    We set $\alert{f(\vect{x})\down} \coloneq \vect{x} \in \domain{f}$ and $\alert{f(\vect{x})\up} \coloneq \vect{x} \notin \domain{f}$.
\end{notation}

\begin{boxdefi}\label{def:pr}
    The set of \alert{partial recursive functions (P.R. functions)} is the subset of $\bigcup_{k \ge 0}(\bN^k \rightharpoonup \bN)$ generated by
    \begin{enumerate}
        \item $0 \colon \bN^0 \to \bN$ is P.R.
        \item $x \mapsto x + 1 \colon \bN \to \bN$ is P.R.
        \item The projection $\proj{i}{k} \colon \bN^k \to \bN,  \proj{i}{k}(x_0, \dots, x_{k-1}) = x_i$ is P.R. for $0 \le i < k$.
        \item Composition: if $f \colon \bN^k \to \bN$ is P.R. and $g_0, \dots, g_{k-1} \colon \bN^l \to \bN$ are P.R. then $f \circ \vect{g} \colon \bN^l \to \bN, x \mapsto f(g_0(\vect{x}), \dots, g_{k-1}(\vect{x}))$ is P.R. and $\vect{x} \in \domain{f \circ \vect{g}}$ iff $\vect{x} \in \domain{g_i}$ for all $i$ and $(g_0(\vect{x}), \dots, g_{k-1}(\vect{x})) \in \domain{f}$.
    \item Primitive recursion: if $f_0 \colon \bN^k \to \bN$ and $f_s \colon \bN^{k+2} \to \bN$ are P.R. then the function $g$ defined by $g(0, \vect{x}) \coloneq f_0(\vect{x})$ and $g(n+1, \vect{x}) \coloneq f_s(n, g(n, \vect{x}), \vect{x})$ is P.R., $g(0, \vect{x})\down$ iff $f_0(\vect{x})\down$, and $g(n + 1, \vect{x})\down$ iff $g(n, \vect{x})\down$ and $f_s(n, g(n, \vect{x}), \vect{x})\down$. 
    \item Minimization (unbounded search): if $f \colon \bN^{k + 1} \to \bN$ is P.R. then $\mu_f \colon \bN^k \to \bN$ is P.R. where we set $\mu_f(\vect{x}) = n$ iff $f(i, \vect{x})\down$ for $i \le n$, $f(i, \vect{x}) > 0$ for $i < n$ and $f(n, \vect{x}) = 0$, and we set $\mu_f(\vect{x})\up$ if no such $n$ exists.
    \end{enumerate}
\end{boxdefi}

\begin{rem}
    \hfill
    \begin{enumerate}
        \item The class of functions closed under the rules (i) to (iv) of Definition \ref{def:pr} are called the \alert{primitive recursive functions}. All  of them are total.
        \item The partially recursive functions that are total are called \alert{(totally) recursive}. Not all of them are primitive recursive functions.
        \item The Church-Turing thesis is the claim that the partially recursive functions are precisely the functions that capture the intuitive notion of ``computability''.
    \end{enumerate}
\end{rem}